{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1729978010954,
     "user": {
      "displayName": "Sean Zhang",
      "userId": "17064777780647407568"
     },
     "user_tz": 300
    },
    "id": "qVkiQmCipvQj",
    "outputId": "df4a03b7-098e-4db0-d001-d3c0fc0b6082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data process.ipynb', 'spam_ham_dataset.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "path=\"/content/drive/MyDrive/CS 410/Bert/dataset\"\n",
    "os.chdir(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1729979297138,
     "user": {
      "displayName": "Sean Zhang",
      "userId": "17064777780647407568"
     },
     "user_tz": 300
    },
    "id": "bxmk17batcDZ",
    "outputId": "592cbee5-c354-4e16-9988-fd6274ffdef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功划分并保存为JSONL文件：train.jsonl、validation.jsonl 和 test.jsonl。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('spam_ham_dataset.csv')[['label_num', 'text']]\n",
    "df.rename(columns={'label_num': 'label'}, inplace=True)\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "def save_to_jsonl(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "save_to_jsonl(train_df.to_dict(orient='records'), 'train.jsonl')\n",
    "save_to_jsonl(val_df.to_dict(orient='records'), 'validation.jsonl')\n",
    "save_to_jsonl(test_df.to_dict(orient='records'), 'test.jsonl')\n",
    "\n",
    "print(\"data has been saved in train.jsonl、validation.jsonl 和 test.jsonl。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1729979300514,
     "user": {
      "displayName": "Sean Zhang",
      "userId": "17064777780647407568"
     },
     "user_tz": 300
    },
    "id": "1NSijfesy4Gb"
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_index_to_jsonl(file_path, output_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    for idx, item in enumerate(data):\n",
    "        item['index'] = idx\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "add_index_to_jsonl('train.jsonl', 'train.jsonl')\n",
    "add_index_to_jsonl('validation.jsonl', 'validation.jsonl')\n",
    "add_index_to_jsonl('test.jsonl', 'test.jsonl')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOQ3iixHNMyQludy9M9yVp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
